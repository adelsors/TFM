{"cells":[{"cell_type":"code","source":["df_train = spark.read.format('csv').options(header=True).load('/titanic/train.csv')\ndf_test = spark.read.format('csv').options(header=True).load('/titanic/test.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["from mmlspark.train import TrainClassifier, ComputeModelStatistics\nfrom mmlspark.automl import FindBestModel\nfrom pyspark.ml.classification import LogisticRegression, LinearSVC, NaiveBayes, DecisionTreeClassifier, RandomForestClassifier\nfrom mmlspark.lightgbm import LightGBMClassifier\nfrom mmlspark.vw import VowpalWabbitClassifier\n\n# Prepare data for learning\ntrain, test, validation = df_train.randomSplit([0.60, 0.20, 0.20], seed=123)\n\n# Train the models on the 'train' data\n# logistic regression\nlrHyperParams = [0.05, 0.1, 0.2, 0.4]\nlogisticRegressions = [LogisticRegression(regParam = hyperParam) for hyperParam in lrHyperParams]\n\nlrmodels = [TrainClassifier(model=lrm, labelCol=\"Survived\").fit(train) for lrm in logisticRegressions]\nlrmodels.append(TrainClassifier(model=LinearSVC(regParam=0.01), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=LinearSVC(regParam=0.05), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=LinearSVC(regParam=0.1), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=LinearSVC(regParam=0.5), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=LinearSVC(regParam=1.0), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=LinearSVC(regParam=1.5), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=LinearSVC(regParam=2.0), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=NaiveBayes(smoothing=0.01), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=NaiveBayes(smoothing=0.1), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=NaiveBayes(smoothing=1.0), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=NaiveBayes(smoothing=2.0), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=LightGBMClassifier(objective='binary'), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=DecisionTreeClassifier(), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=RandomForestClassifier(numTrees = 5), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=RandomForestClassifier(numTrees = 10), labelCol=\"Survived\").fit(train))\nlrmodels.append(TrainClassifier(model=VowpalWabbitClassifier(numPasses=10), labelCol=\"Survived\").fit(train))\n\nbestModel = FindBestModel(evaluationMetric=\"accuracy\", models=lrmodels).fit(test)\n\n# Get accuracy on the validation dataset\npredictions = bestModel.transform(validation)\nmetrics = ComputeModelStatistics().transform(predictions)\nmetrics.createOrReplaceTempView(\"classMetrics\")\nmetrics.show()\n\nprint(\"Best model's accuracy on validation set = \" + \"{0:.2f}%\".format(metrics.first()[\"accuracy\"] * 100))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+--------------------+------------------+------------------+------------------+------------------+\nevaluation_type|    confusion_matrix|          accuracy|         precision|            recall|               AUC|\n+---------------+--------------------+------------------+------------------+------------------+------------------+\n Classification|102.0  6.0   \n28....|0.8142076502732241|0.8867924528301887|0.6266666666666667|0.8657407407407403|\n+---------------+--------------------+------------------+------------------+------------------+------------------+\n\nBest model&#39;s accuracy on validation set = 81.42%\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["import pandas as pd\n\n# Get predictions on the test dataset\npredictions = bestModel.transform(df_test)\nscored = predictions.select('scored_labels').toPandas()\npreds = pd.DataFrame({'PassengerId' : range(892,1310), 'Survived' : scored['scored_labels'].astype(int)})\npreds.to_csv('/dbfs/titanic/results-mmlspark.csv', index=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python","file_extension":".py"},"name":"Titanic - mmlspark","notebookId":2836894922187580,"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"anaconda-cloud":{},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"nbformat":4,"nbformat_minor":0}
